During the inception of indoor localization research with WLAN as the background, the technique utilized to deduce a user's location is called 'nearest neighbour(s) in signal space'(NNSS) \cite{radar}, whose marrow is calculating the Euclidean distance between RSSes stored in the database and RSSes measured during localizing. NNSS outputs the location minimizing that distance as the ultimate estimation of the user¡¯s location. However, NNSS still dangles the possibility of accuracy enhancement in that it fails to realize the joint location estimation from multiple APs \cite{castro01}.  
In order to take advantage of these multiple APs, Chintalapudi \emph{et al.} bring up an algorithm entitled as EZ localization, whose main contribution occurs in estimating mobile devices without any pre-deployment support of multiple APs \cite{Chintalapudi10}. EZ will learn from those acquired fingerprints, which reflect the value of mean and standard deviation of the RSSes corresponding to different APs, during the collection phase. 
%The key point of EZ is that it is erected on the fact that the physics of wireless propagation constrain the fingerprints reported to the server, and it models these constraints and couples them with a genetic algorithm to get the final solution. 

\subsection{Indoor localization model}
One of the common and convenient approaches to collect fingerprints used in Indoor localization is crowdsourcing. Wu \emph{et al.} design a localizing system LiFS, combining indoor localization with crowdsourcing and bypassing the conventional site survey process \cite{Yang12,Chenshu14}. They initially place several landmarks in the physical space, and then harness information from user motions and pinned sensors in smart phone to set up a sample space with high dimension. %The materialization of this sample space relies on Multidimensional Scaling(MDS) algorithm, visualizing the information of similarities and dissimilarities concealed in data \cite{Yang12}. Meanwhile, since the high-dimensional space generated by MDS can be applied to characterize the physical space as well, the estimation of a user¡¯s location can be derived via comparing physical space and sample space with high dimension.
%More utilization of crowdsourcing method has been revealed. 
Rai \emph{et al.} develop a system called Zee to enable zero-effort crowdsourcing \cite{Rai12}. %which denotes that no explicit effort on the part of users is needed  
While a mobile device is traversing indoors scanning Wi-Fi signals, Zee leverages inner sensors of the device to track the device itself. Shen \emph{et al.} also present a crowdsourcing based system \emph{Walkie-Markie} \cite{walkie} to generate indoor pathway maps from the user contributed data. %The central idea of the system is to exploit Wi-Fi-Marks defined by Wi-Fi RSS features in the indoor space, so that crowdsourced data can be fused.
%Luo \emph{et al.} propose a self-calibrating participatory indoor localization system \cite{piloc}, which requires no prior knowledge about the building and user intervention including the floor planning. %Additionally, Crowdsourcing approach has also been applied to various domains such as transportation \cite{transportation2}, environment surveillance \cite{environment, environment2} and location based service \cite{lbs,Wen2015Quality}.

%Nevertheless, the above work has not placed a premium on the fingerprint procurement phase, just concluding this procedure as crowdsourcing. In fact, more complex situations should be underscored in realistic fingerprint acquirement. %For instance, we need to hire fingerprint samplers to collect fingerprints to construct our database, and our budget is limited practically, therefore probably we cannot buy all sampled fingerprints. How should we offer our price to fingerprints from each sampler, maximizing localizing accuracy with the fixed budget? Perhaps samplers come in a batch or a queue, so what is the optimal purchasing strategy for these two conditions respectively?


\subsection{Incentive design for crowdsourcing}
%In realistic situations, data providers are not always willing to sell their data to us for sundry reasons such as dissatisfying with the price we offer compared with the estimated cost in their mind or worrying about data privacy. To cope with this problem, the incentive mechanism should galvanize them to supply us with their data, with means like offering them compensation. Furthermore, given that the data we need are required to be accurate enough, incentive mechanism should assure good quality of collected data. %and ii) truthfulness, which means that the mechanism should let data providers to report the cost of their data identical to the expected cost in their mind rather than raising their reporting cost arbitrarily. %The core of the `persuasion¡¯ is to assure data providers that they cannot receive higher profits than reporting their true cost in mind, thus they have no intention to mount their reporting cost.

Peng \emph {et al.} 
%point out the deficiency induced by continuous data with poor quality to the preciseness and availability of services predicated on crowdsensing in conventional incentive mechanism designing, and they
bring up an incentive mechanism both stimulating data provision and ensuring high quality \cite{Peng2015Pay}. Jin \emph{et al.} introduce a key metric, quality of information(QoI), which generally evinces the quality of users¡¯ sensory data%but whose definition varies among different applications
\cite{Jin2015Quality}. Taking QoI into consideration, the incentive mechanism can acquire data with higher quality making for further study like better identification for problems of medical devices \cite{Jin2015Quality}.\\
 %For instance, in the MedWatcher system, QoI represents the quality of a photo and higher quality photos got from the mechanism contribute to better identification for problems of medical devices. %Stepping further, Jin \emph {et al.} study the auction models used for single-minded and multi-minded cases respectively, where every user is set to execute a single subset of tasks in single-minded situations while execute multiple subsets of tasks in multi-minded scenarios. In single-minded situations a truthful and individual rational incentive mechanism is designed while in multi-minded ones an iterative descending mechanism is derived, both of which approximately reach their common objective--the optimal social welfare with an approximation ratio guaranteed.
%Peng \emph {et al.}
%point out the deficiency induced by continuous data with poor quality to the preciseness and availability of services predicated on crowdsensing in conventional incentive mechanism designing, and they
%also bring up an incentive mechanism to stimulate data provision and guarantee high quality \cite{Peng2015Pay}. Their concrete recipe is abstracted as follows. They firstly measures each participant's effort in contributing data by an effort matrix. %attaching the expectation maximization(EM) algorithm to settle the problem that the true reading cannot be made certain in most conditions.
%Then the mechanism calculates the quality of every user's data and figure out the user's efficient contribution on the foundation of the effort matrix. Finally %with the objective of galvanizing participants to hand in high quality sensing data,
%the mechanism supplies participants with rewards in correspondence with their effective contributions.\\
\indent In terms of new facets refreshing incentive mechanism research, Tham and Luo take timeliness of contributions into consideration \cite{Tham2013Quality}. %They characterize the quality of data as Quality of Contributed Service (QCS), which can be explained as follows: the more contributions, or the higher the quality of them, or the more up-to-date they are, the higher is the value of QCS. The up-to-date measurement of contributions reflects the influence of timeliness of contributions.
Specifically, They assume that the usefulness of data contributed by a user will go downhill with time and may ultimately be of no worth. By incorporating the temporal factor, they render the mechanism more analogous to realistic scenes such as employees will only get salaries a month later.
%the contributor will receive rewards after a period of time when they contribute their data, akin to
  %Nevertheless, their work is under the assumption of offline situation which deviates from our online background, and we do not involve timeliness of information in our work.
Kawajiri \emph{et al.} also provide a novel framework, Steered Crowdsensing, which aims to level up the quality of acquired data directly rather than the data size, pinpointing the problem that monetary pressure and time consumption perhaps ascend to an unbearable extent when the quantity of data is up-scaled \cite{Kawajiri2014Steered}.\\ %Steered Crowdsensing can be concluded as the following process. Users are initially given incentives by points of each location and they are required to collect data of these points. Then users will determine whether and where to gather data in light of points of each location.
%The crucial part of Steered Crowdsensing is that according to the analysis of the collected data, a kind of feedback will be brought out to steer the points, making for the enhancement of quality of data. Meanwhile, steered Crowdsensing keeps the quantity of data collected in control via incentive controlling methods, one of which is gamification. %What is similar to our work is that both apply their own incentive mechanism to the situation of indoor localization, while it is not concerned with online learning.
\indent However, the work mentioned above in this subsection except \cite{Kawajiri2014Steered} does not fit the incentive mechanism into indoor localization, which is not necessarily suitable in our work. How can incentive mechanism be properly utilized in the data procurement phase of localizing? Wen \emph{et al.} tailors quality-based incentive mechanism into a Wi-Fi fingerprint-based indoor localization system \cite{Wen2015Quality}. %Their mechanism can be interpreted as a worker will be paid based on the quality of sensory data procured in lieu of working time.
Moreover they present a stochastic model to assess the reliability of sensed data, crystallizing the measurement of quality of data under localization background. %In detail, They convert the unreliability of data into that of the user's sense of locality which can be profiled by experiments in advance. The profile of a user's sense of locality reflects the probability of a user's incorrectness of locality.
%which specifically means that a user may offer the data of the location where he regards but in fact he is at another location.
%The probabilistic information is then harnessed to discover the data with highest reliability. 
This probabilistic model is contained within their mechanism. Kawajiri \emph{et al.} also test their Steered Crowdsensing framework under the background of indoor localization \cite{Kawajiri2014Steered}. However, their models function in offline conditions, differing from our online ones depicted in the next subsection. %whose problem setting is that the data providers come in a queue instead of a batch and data buyers need to decide whether to purchase the coming data at once.
 Zhang \emph{et al.} cope with the situation where the goal is to incentivize a batch of workers to label some binary tasks with a budget constraint \cite{zhang2015incentivize}.
 
\subsection{Online learning}

Online learning is one of the dominant mathematical models our work utilizes. It is generally carried out in the situation where there are continuous question-and-answer rounds and a question comes up in each round. The learner is required to predict an answer of the question in current round. After that the correct answer will be presented to the learner. The learner will suffer a loss reflecting the discrepancy between this prediction and the true answer, and then the learner continues to the next round. The ultimate goal of the learner is to minimize the loss or other parameters related to it \cite{shalev2011online}.%One of the most notable properties of the learner¡¯s prediction in a round is that it can be depended on historical information learned from previous rounds so that a more reasonable answer will be given in this round. For instance, one can offer a prediction in $t$-th round which minimizes the sum of previous $t-1$ loss functions, rendering it as an optimization problem \cite{abernethy2015low}. In fact, online learning problems are tied tightly with online optimization \cite{shalev2011online}.

%There are assorted theoretical studies pertinent to online learning. Shalev-Shwartz sorts out a refined survey about the theory \cite{shalev2011online}. He summarizes classical methods such as Follow-the-Regularized-Leader(FTRL) and Online-to-Batch Conversions(OBC) in online learning. %Furthermore he presents some typical applications of online learning methods composed of online classification, multi-armed bandit problem and so on.
Zinkevich introduces an effective algorithm: Generalized Infinitesimal Gradient Ascent (GIGA), which formulates a common form of online optimization algorithm \cite{zinkevich2003online}. However, these fundamental analyses do not touch the usage of online learning in practical models, which means that the classical methods need modifications before being fit in with specific industrial objectives. 

Execution of online learning theory in realistic models has been materialized. Abernethy \emph{et al.} embed the theory into online data procurement $T$ rounds \cite{abernethy2015low}. 
%The concrete problem setting is as follows. A data collector has to purchase data with a limited budget $B$, and the mechanism posts a price $\pi$ of the coming data to an agent in each round. After that the agent acquires the true cost $C$ from the data provider and compare it with $\pi$, if $\pi > C$ then the transaction is achieved with data, cost and loss learned by the mechanism, or else the deal fails with nothing learned. The terminate goal is to propose a pricing strategy reaching the lowest regret, which represents the difference between loss of our pricing hypothesis and that of the theoretically optimal one. They apply the FTRL and OBC to settle this problem with the final result a regret bound of $O(T/\sqrt{B})$. However, this work makes some assumptions controversial in reality for simplification due to the inaccessibility to the final answer of original problem, such as if a deal is closed the mechanism will only pay $C$ in lieu of practically $\pi$. What¡¯s more, they only endow abstract meanings of parameters in their work, thus for more specific work like indoor localization the concrete meaning of data, cost, loss and so on should be clarified.

In our work we carry out some adjustments over the framework of \cite{abernethy2015low} to fit into indoor localization background. We inject particular meanings to the parameters in our context. Data is the received signal strength(RSS) offered by signal samplers, 
%and cost is the money we should pay for RSS values from samplers, while 
we define loss is the localizing error we suffer using data we have purchased. Moreover the prediction in each round is the estimated RSS value given by the mechanism. 
%in accordance with sampled RSS values, while regret is the distance between estimation and true value of RSS at this location.Deeper technical modifications of the model in \cite{abernethy2015low} will be displayed in the next subsection.

%Another research point lies in the budget constraint of the online optimization problem. In \cite{abernethy2015low}, Abernethy \emph{et al.} simplify the optimization by loosing the budget constraint for the complexity of integral in the expression of cost expectation. However, it leaves the probability that the optimal result output by mechanism in \cite{abernethy2015low} may not make the regret bound tight enough, or even the output is infeasible in the original problem setting for constraint relaxing. In order to reaching a more precise solution, we directly solve the initial problem without relaxation by means of calculus variation. Calculus variation is associated with functional theories, viewing functions as decision variables, and it can derive the exact solution of functional optimization
 \cite{liberzon2012calculus,roth2012conducting}. %In our work decision variables are cumulative distribution functions reflecting the probability of buying data in each round.
With calculus variation applied, we derive the accurate pricing strategy for this problem.

\section{System Model}\label{sysmodel}
In this section we describe our system model and give out the problem formulation.

As shown in Figure~\ref{}, we present a mobile crowdsensing system consisted of \emph{Data Purchasing mechanism}. For the purpose of performing accurate indoor localization in region $\mathcal{V}$, the data purchaser has to build the corresponding \emph{Fingerprint Database} of \emph{Received Signal Strength}(RSS). Therefore the data purchaser releases tasks of collecting data--RSS value on the platform. For a specific location $s\in \mathcal{V}$, we use $\mathds{W}_s=\{w_1,w_2,...,w_{N_s}\}$ to denote the corresponding applicants set. To simplify the notation, we omit the identification of $s$ in almost all the rest of this paper. Without loss of generality, we mainly focus on workers with the same location's data. It's rational that data purchaser need to buy several data points at one location since the RSS value is not constant, in fact it obeys some probability distribution, we assume that its probability density function is $\mathcal{D}(\cdot)$. Consequently, we need several amounts of samples to learn the distribution, more specifically, to estimate the mean value of RSS.

At the very beginning, the data purchaser needs to submit his \emph{Pricing Mechanism} $\mathbb{M}$ to the platform. Here we consider the most nature trading scenario: these $N$ workers arrive in a sequential way with his data $x_i$. Once agents $i$ arrives, he submit his bid $c_i$ to the platform and the platform compute its price $p_i$ using a mechanism $\mathbb{M}$. If $p_i\geq b_i$ then agents $w_i$ accept this transaction: the platform pays $b_i$ to worker $i$ and receives data $x_i$, otherwise the worker reject the transaction and the platform receives null signal.